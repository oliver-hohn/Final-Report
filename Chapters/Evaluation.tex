\chapter{Evaluation}
-present how did analysis, why?, other options (relate to work)
-results of analysis
-conclusion
\par As was presented in the Design chapter, the objectives of the system are: visibility, efficiency, and effectiveness. To evaluate each of these the chapter is split into three sections. Each section adresses each keypoint.
%\section{Software Testing}
\section{Visibility}
-explain expert heuristic
-knowledge of expert
-that this is the least important of the three as the ui can be built by third party and only processing is used.
\section{Efficiency}
\par Efficiency relates to the time it takes for the system to produce an answer. A system is efficient if it produces a result in an appropriate amount of time based on its input.
\par A way to evaluate this is to run the system on different inputs and record the time taken to produce a timeline. However, the time recorded is specific not only to the machine that the system is being run on, but also the other workload the machine has. If the system is ran with many other 3rd party tasks running in the background then the time will be longer than if it is the only process running. In addition, different machines with different hardware parts may be faster or slower depending on the number of cores of the system, and how the workload is scheduled (cite). The Operating System could also affect this (cite). Also, not all different input sizes can be tested, as the document set size can be infinite. The solution is to consider the time complexity of the main algorithms of the system. The time complexity of an algorithm is, the number of operations that need to be carried out for an input of a given size (cite). This allows to determine how well the system scales with larger inputs, by only considering how many operations are performed as a function of the input.
\par Time complexity focuses on the worst case situation, and does not consider low-order operations. For example, if for an input $n$ an algorithm performs $3n+2$ operations, the low-order term $2$ and the co-efficient $3$ can be omitted. This would result in a time complexity $O(n)$ (where $O$ is called big-Oh). In general the highest order-term is taken, and all the rest are omitted. For example, for $4n^2+10n+2$ would have time complexity $O(n^2)$.  The low-order terms are omitted as with a very large input, or as ${n\to\infty}$ the effect of the number of operations of the low-order terms becomes smaller to irrelevant. The co-efficient of the high-order term is omitted, as a machine can be 4 times faster, or 4 times slower, so it does not affect the greately the number of operations performed.
\par To measure the efficiency of the system, the time complexity of the front-end (graphical part) and back-end (logical part) of the system have been computed separately, as the system can be used as a library to produce a list of events to then use in a separate 3rd party graphical representation.
\subsection{Back-End}
\subsubsection{Processing Documents}
\par The two main algorithms are the processing of documents, and the production of Ranges. The complexity of each will be presented and discussed. It assumes the complexity of annotating the text in the documents is $O(w)$ (for all $w$ words in the document), and that the documents are annotated before being processed.
\par The algorithm of processing documents is presented below (see Algorithm \ref{alg:documentsProcessing}). For a list of $n$ documents, it processes each. It can process $x$ documents in parallel at a time. Depending on the users setting value $x$ can be 1 or ${x\to\infty}$ ($x$ tends to infinity). If ${x\to\infty}$, then it can be determined that the complexity of the algorithm is given by complexity of processing 1 document (the largest). As all documents are processed in parallel. \par When a document is processed (see algorithm \ref{alg:processDocument}), each sentence is checked for a temporal expression, before a summary or any other processing is done. In the worst case, all sentences $s$ in a document have to be fully processed. In such a case, the date, the subjects, and the summary need to be performed. These are all done after each other, so it can be determined that the computation complexity of processing one sentence is given by $max(getDate, getSubjects, getSummary)$. Where $max$ will return the greates time complexity of the three operations. 
\par To get the date of a sentence, with $w$ words, each temporal expression needs to be processed. The processing of a temporal expression is linear (see the getDate algorithm presented in the Implementation Chapter), as it does not depend on the input directly, it performs less than 3 steps depending on how much the temporal expression can be broken up to. In the worst case, every word in the sentence is a temporal expression (which does not happen normally in a sentence of well-written document, but it can still occur, and the focus is on the worst case). Thereby, the time complexity for getDate is $O(w)$.
\par To select the subjects of a sentence, the NER(footnote) annotator is used to determine which words are of interest. In the worst case, all words can be of interest. The words are not processed when selected, thereby the time complexity of selecting all the subjects in a sentence is $O(w)$.
\par To create the summary of a sentence, with $w$ words, the hedge-trimmer algorithm is used (see the Algorithm presented in the Design Chapter). In the paper, the time complexity of the algorithm is not presented as the algorithm is not explicitly provided, but rather explained. Thereby, the algorithm implemented was analyzed. As a grammatical tree is produced, and each word in the sentence is a leaf. The structure of the tree varies, however it can be assumed that the worst case grammatical tree produced is a full-binary tree. If there are $w$ leaves in the tree (i.e. each word in the sentence is a leaf), then there are $2w-1$ nodes in the tree. The rules of the algorithm are applied one after the other. Thereby, the time complexity is given by the rule with the highest time complexity. The first two rules traverse the tree once (at most), hence have a complexity $O(2w-1) = O(w)$. The last step, where the tree is iteratively shortened, it is done until the tree is below the threshold. In the worst case, the threshold can be 0 (not allowed in the program as the minimum threshold value is 0). Note that the threshold value is the number of leaves. At each step, for the algorithm to continue, at least one node needs to be removed. However, if an inner node is removed then its children (including the leaf is removed, thereby getting closer to the threshold value of 0). At each step the tree needs to be traversed. Thereby, traversing a tree (as presented earlier) has complexity $O(w)$, which is done in the worst case $w$ times (i.e. a word is removed each time, until the word count is 0, and the threshold has been reached).Thereby, the complexity to create a summary is given by $O(w^2)$.
\par Therefore, the processing of a sentence with $w$ words is given by $O(w)+O(w)+O(w^2)$, which can be simplified to $O(w^2)$ (removed low order terms). Assuming that the set of $n$ documents is processed one after the other (i.e. at most 1 document can be produced in paralled), and that all the documents have $s$ sentences (or less). Where each sentence has $w$ words (or less). The running time of processing one document is $O(sw^2)$. Then the running time of processing $n$ documents is $O(nsw^2)$. Where it is not known whether $n$, $s$, or $w$ is the high-order term. The time complexity of annotating a document is omitted as it can be considered that $sw^2 > w$.
\par If the system consists of many documents, with less sentences that do not have many words, then the running time is given by $O(n)$. Which is extremely efficient for processing $n$ documents, as it suggests that the system will increase in processing time linearly with the input size of the number of documents. Thereby, producing a high efficiency as it scales linearly with input.

\subsubsection{Range Production}
\par Ranges are produced with the algorithm presented in the Design Chapter (??). Based on an input of $n$ Results, they have to be sored, added to existing Ranges or create new Ranges, and then sort the Ranges.
\par Sorting Results in Java has a complexity of $O(n\log n)$. This is due to Java using merge-sort when comparing the results (footnote). Merge-sort consits of recursively breaking down the problem space in half (which produces the $\log n$ part), and then building the sequence back up (which produces the $n$). However, it should be noted that with sequences that are almost sorted Java 8+, will have a time complexity of $O(n)$ as it uses TimSort\footnote{\url{https://bugs.openjdk.java.net/browse/JDK-6804124}}. 
\par Each Result needs to be added to the trees. As before it is added to a tree, it is checked whether or not it should be added to that Range tree (by checking  if the dates of the Result and Range overlap), not all trees need to be traversed completely to add the Result. In the worst case, all trees at that point need to be checked and a new tree needs to generated to hold this Result. This can be the case when the dates of events are all completely disjoint.  In such case, the amount of Trees that need to checked increases by 1 for each Result added. Assuming that the time complexity to check whether a Result can be added to a tree is $O(1)$, then the time complexity is given by the sum of 0 to $n$. As in the first step, no Ranges exist so nothing needs to be checked. Then one tree needs to be checked, then two trees, and so on. Where at the $n$th Result, $n-1$ trees need to be checked, each with a complexity $O(1)$. Threby, the total complexity is given by the sum of 0 to $n$, which is given by ${n(n+1)}/2$. This produces a time complexity $O({n^2+n}/2)$, which is $O(n^2)$.
\par After all the trees have been produced, then the Ranges need to be sorted. Where in the worst case there is one full expanded tree. Which is a tree where for each Result it had to be expanded, because the dates overlapped (but where never fully contained within each other). This leads to a full binary tree due to how the trees are expanded by producing a expanded node, with a new node that holds the new Result, and the older subtree on the left. Where the $n$ Results are on the leaves, so there are $2n-1$ nodes. Which using the Java sorting algorithm leads to $O(n\log n)$.
\par Thereby, the time complexity of the Range Production algorithm is given by its greatest complexity of its operation. Which the adding of Results to the tree. Therefore, its time complexity is $O(n^2)$.
\subsection{Front-End}
\par In this section the focus is on the creation of the range and traditional timeline views.
\subsubsection{Range View}
\par As can be seen by the algorithm to produce the Range view (??), it considers each Range separetely when building it. In the worst case, there is one Range with a fully expanded tree (i.e. a full binary Range tree). If the tree holds $n$ results, which are held at the leaves, then it has a total of $2n-1$ nodes. For all nodes it must produce a layout, which includes the production of its children recursively. Therefore, $2n-$ layouts are produced, so the time complexity is given by $O(n)$. 
\par There can be performance issues, as there are embedded layouts, and many views being created and graphically shown. However, the focus in this section is to consider the time for the system to produce the UI, not how heavy it is for the system's memory.
\subsubsection{Timeline UI}
\par The creation of the timeline view is trivial. For a list of $n$ results, the layout for each row of the listview is produced. Hence, $n$ rows are produced. This leads to a time complexity of $O(n)$.
\par It should be noted that the ListView used in the system does not hold all rows in memory at once. The layout of a row is only produced if it needs to be shown, i.e. that part of the ListView is visible to the user (cite). Hence, the time complexity to produce the timeline view is less than $O(n)$, as the system does not show all the Results. Only when the size of the ListView is smaller than the amount of allocated screen space it is given, will it have to produce $n$ rows, and thereby have a time complexity of $O(n)$.
\section{Effectiveness}
-how did you test?
-participants data?
-safeguard participants
-data set
-why test this way