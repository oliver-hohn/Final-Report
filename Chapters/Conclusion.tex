\chapter{Conclusion and Future Work}

The project's conclusions should list the key things that have been learnt as a consequence of engaging in your project work. For example, ``The use of overloading in C++ provides a very elegant mechanism for transparent parallelisation of sequential programs'', or ``The overheads of linear-time n-body algorithms makes them computationally less efficient than $O(n \log n)$ algorithms for systems with less than 100000 particles''. Avoid tedious personal reflections like ``I learned a lot about C++ programming...'', or ``Simulating colliding galaxies can be real fun...''. It is common to finish the report by listing ways in which the project can be taken further. This might, for example, be a plan for turning a piece of software or hardware into a marketable product, or a set of ideas for possibly turning your project into an MPhil or PhD.

-what have you learned?
-how can the project be carried further (neural net for summary, building on the StanfordCoreNLP for detas depending on others)
\section{Conclusion of Project}
\par In conclusion, the project aimed to build an automated event extraction from documents, and then produce a timeline with the events. It was largely built on top of the StanfordCoreNLP tool, that was used to categories sets of words into predefined categories (NER annotator) and build grammatical trees (POS annotator). In addition, a trimming algorithm was used to produce headlines of sentences (i.e. summaries). The use of multi-threading allowed for parallel processing of documents, and thereby quicker result times in producing the timeline as oppossed to processing the documents one after the other. 
\par The project is aimed to be open-source, as it may be required by some of the libraries used, and allows for its integration into other projects, where another appropriate graphical view is required, or the event data is processed even further. This is eased through the use of Gradle, and its produced wrapper, as it retrieves the appropriate libraries for the user and allows them to run the system with a simple comman\footnote{gradlew run}. An effort was made to produce a documented set of code, that is independent of its graphical counterpart. Especially through the use of the produced intermediate JSON for the timelines. Thereby, the back-end of the system can be integrated as an API (Application Programming Interface) into other projects. 
\par Issues occurred, and new requirements appeared during the production of the system. These include the creation of exact dates from normalized dates, wrong input documents, and the encapsulation of events for a new timeline view. These issues were identified and appropriately solved. Ofcourse, as with any project, the initial design was changed, but through using an Agile methodoly this could be tackled and did not hinder greately the implementation of the system. Changes include minor changes in the systems architecture to allow for the independence between the logic of the system and its graphical representation.
\par The use of running time complexity allowed the system's efficiency to be evaulated independently on the system in which it will run, and on the data size. Providing an expert a herusitic allowed for the evaluation of the front-end of the system, as the heuristics have been clearly tested priorily and are a standard. From the effectiveness evaluation it can be determined that the system is effective at identifying events in documents of different domains (especially newspaper articles), however the summary of sentences that are identified as events requires further work (discussed in the following section). Ofcourse, with additional time and resources new features (such as the ones discussed in the Future work section) could be developed, and more test participant data can be gathered to perform statistical analysis that can point to how significant the results gathered are (using a t-test). 
\par 
\section{Future Work}
-neural bet, cloud, building on tool to link to ambigious dates that are related to other possible known ones, edit events (machine-learning in addition to neural net)
\par Future works consist of areas of possible development that would improve the overall effectiveness of the system. The areas are described below. Implementing any of these would be an improvement, however the challenge is in being able to combine them all to produce a system that can be used at a commercial level, and would be unrivalled by other systems.
\par \textbf{Neural Net} - As mentioned in the Background Chapter, there is a heavy use of Neural Nets for text summarization, as can be seen from the works of \cite{chopraaulirush2016} and \cite{rushchopraweston2015}. These are often combined with noisy-channel models that use data sets for statistcal computation of summaries. The main benefit of such a system would be to provide better summaries. The reason for them not being used in the project is the large data set required and the amount of computation done to produce a summary of one sentence.
\par \textbf{Machine Learning} - Machine learning allows a system to become more accurate by incrementing its data set, and it then being used to produce outputs (cite). It is similar to Neural Nets. In this system it could be used in the production of events, as follows. When a user edits an event it can be assummed that they produced a corrected event. This data can then be used and considered in the creation of other events by the system, to produce more precise ones. Thereby gradually improving the system.
\par \textbf{Cloud} - A cloud allows a service to be provided independent of its software and hardware (cite). This is done by deploying the system on a remote server, and giving clients an interface to interact with it. Thereby it is not required for the client to have a powerful machine, and it does not affect their systems performance. The downfall is the cost. However, the performance could be improved as specific hardware could be used to improve the efficiency and it could be combined withMachine-Learning and Neural Nets to allow the system to impove in its event identification and production.
\par \textbf{Extending StanfordCoreNLP} - An issue in the tool used, is that it does not attempt to link ambigious temporal expressions. For example, it may be known that an event occurred before another. For example, a person has to be born first before they can work (example taken from \cite{mccloskymanning2012}). In the system when an exact date cannot be given an ambigious one is produced. For example, for both born and working it could produce a "PAST\_REF". This would then cause the system to assign both events to the same range of dates, i.e. 0001-01-01 up to the reference point used for the document. However, these can be made more precisely.  Since a person has to be born first, and be over the age of 16 to work. Thereby the range of dates for the work event could be identified more precisely. The problem arises, from the tool and the produced system considering each sentence independently of each other. It would be benefitial if the events were to be linked one after the other, such that it may not be known when someone was born or when they worked, but that the event of them working is after the event of them being born. This would require building on the NLP tool used in the system.